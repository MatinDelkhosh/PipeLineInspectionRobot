{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiQaDlLZOI8O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from google.colab import files\n",
        "\n",
        "# âš¡ 1ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯ÛŒØªØ§Ø³Øª Ùˆ ØªØ³Øª\n",
        "uploaded = files.upload()\n",
        "!unrar x bump_on.rar\n",
        "!unrar x test.rar\n",
        "\n",
        "dataset_path = \"bump_on\"\n",
        "test_path = \"test\"\n",
        "\n",
        "# ğŸ“Œ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØªÙˆØ§ÛŒ ÙÙˆÙ„Ø¯Ø±Ù‡Ø§\n",
        "print(\"ğŸ“‚ Ù…Ø­ØªÙˆØ§ÛŒ bump_on:\")\n",
        "!ls -l bump_on\n",
        "\n",
        "print(\"\\nğŸ“‚ Ù…Ø­ØªÙˆØ§ÛŒ test:\")\n",
        "!ls -l test\n",
        "\n",
        "# ğŸ”¹ 2ï¸âƒ£ Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø§Ø² classes.txt\n",
        "classes_file = os.path.join(dataset_path, \"classes.txt\")\n",
        "with open(classes_file, \"r\") as f:\n",
        "    class_names = [line.strip() for line in f.readlines()]\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"\\nğŸ”¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒØªØ§Ø³Øª: {class_names}\")\n",
        "\n",
        "# ğŸ“ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµØ§ÙˆÛŒØ±\n",
        "img_size = (224, 224)\n",
        "\n",
        "#  3ï¸âƒ£ ØªØ§Ø¨Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¨Ø¯ÙˆÙ† Ù„ÛŒØ¨Ù„)\n",
        "def load_images(folder, labeled=True):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(folder, file)\n",
        "\n",
        "            # Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if img is None:\n",
        "                print(f\"âš ï¸ ØªØµÙˆÛŒØ± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            img = cv2.resize(img, img_size) / 255.0\n",
        "            images.append(img)\n",
        "\n",
        "            # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ø§ÛŒ Ù„ÛŒØ¨Ù„ Ù‡Ø³ØªÙ†Ø¯ØŒ Ù„ÛŒØ¨Ù„ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†Ø¯\n",
        "            if labeled:\n",
        "                txt_path = img_path.replace(\".jpg\", \".txt\")\n",
        "                if os.path.exists(txt_path):\n",
        "                    with open(txt_path, \"r\") as f:\n",
        "                        try:\n",
        "                            class_id = int(f.readline().split()[0])\n",
        "                            labels.append(class_id)\n",
        "                        except:\n",
        "                            print(f\"âš ï¸ Ù…Ø´Ú©Ù„ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„Ø§Ø³ Ø§Ø² {txt_path}\")\n",
        "                            labels.append(0)  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶\n",
        "                else:\n",
        "                    print(f\"âš ï¸ ÙØ§ÛŒÙ„ Ú©Ù„Ø§Ø³ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {txt_path}\")\n",
        "                    labels.append(0)  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶\n",
        "\n",
        "    print(f\"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø§Ø² {folder}: {len(images)}\")\n",
        "\n",
        "    if labeled:\n",
        "        return np.array(images), np.array(labels)\n",
        "    else:\n",
        "        return np.array(images)  # ÙÙ‚Ø· ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯\n",
        "\n",
        "#  4ï¸âƒ£ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "X_train, y_train = load_images(dataset_path, labeled=True)\n",
        "X_test = load_images(test_path, labeled=False)\n",
        "\n",
        "print(f\"\\nâœ… ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ø¢Ù…ÙˆØ²Ø´ÛŒ: {len(X_train)}, ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± ØªØ³Øª: {len(X_test)}\")\n",
        "\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(min(5, len(X_test))):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(X_test[i])\n",
        "    plt.title(f\"Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {class_names[predicted_labels[i]]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ]
}