{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuqlqpMEM6Mh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# âš¡ 1ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„ Ù…Ø¯Ù„\n",
        "#uploaded = files.upload()  # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ Ù…Ø¯Ù„\n",
        "MODEL_ZIP_PATH = \"centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz\"\n",
        "MODEL_DIR = \"centernet_mobilenetv2_fpn_od\"\n",
        "SAVED_MODEL_PATH = os.path.join(MODEL_DIR, \"saved_model\")\n",
        "#SAVED_MODEL_PATH = \"saved_model\"\n",
        "\n",
        "# ðŸ—‚ï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ Ù…Ø¯Ù„ Ø§Ú¯Ø± Ø§Ø² Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯\n",
        "if not os.path.exists(SAVED_MODEL_PATH):\n",
        "    print(\"ðŸ“¦ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¯Ù„...\")\n",
        "    !tar -xvf {MODEL_ZIP_PATH}\n",
        "else:\n",
        "    print(\"âœ… Ù…Ø¯Ù„ Ø§Ø² Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª.\")\n",
        "\n",
        "# ðŸš€ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„\n",
        "print(\"ðŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„...\")\n",
        "model = tf.saved_model.load(SAVED_MODEL_PATH)\n",
        "print(\"âœ… Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯!\")\n",
        "\n",
        "# âš¡ 2ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª\n",
        "#uploaded = files.upload()\n",
        "!unrar x test.rar\n",
        "TEST_PATH = \"test\"\n",
        "\n",
        "# ðŸ“Œ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØªÙˆØ§ÛŒ ÙÙˆÙ„Ø¯Ø± ØªØ³Øª\n",
        "print(\"\\nðŸ“‚ Ù…Ø­ØªÙˆØ§ÛŒ test:\")\n",
        "!ls -l test\n",
        "\n",
        "# ðŸ“ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµØ§ÙˆÛŒØ±\n",
        "img_size = (320, 320)\n",
        "\n",
        "# ðŸ“Œ 3ï¸âƒ£ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ± ØªØ³Øª\n",
        "def load_test_images(folder):\n",
        "    images = []\n",
        "    image_paths = []\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(folder, file)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if img is None:\n",
        "                print(f\"âš ï¸ ØªØµÙˆÛŒØ± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯: {img_path}\")\n",
        "                continue\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_resized = cv2.resize(img, img_size)\n",
        "            images.append(img_resized / 255.0)\n",
        "            image_paths.append(img_path)\n",
        "    print(f\"âœ… ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± ØªØ³Øª: {len(images)}\")\n",
        "    return np.array(images), image_paths\n",
        "\n",
        "X_test, image_paths = load_test_images(TEST_PATH)\n",
        "\n",
        "# ðŸ“Œ 4ï¸âƒ£ ØªØ´Ø®ÛŒØµ Ø§Ø´ÛŒØ§ Ø¯Ø± ØªØµØ§ÙˆÛŒØ± ØªØ³Øª\n",
        "def detect_objects(model, images, image_paths):\n",
        "    detect_fn = model.signatures[\"serving_default\"]  # Ú¯Ø±ÙØªÙ† Ù…ØªØ¯ Ù…Ù†Ø§Ø³Ø¨\n",
        "    for i, img in enumerate(images):\n",
        "        input_tensor = tf.convert_to_tensor([img], dtype=tf.float32)\n",
        "        detections = detect_fn(input_tensor)\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§Ù†Ø¯ÛŒÙ†Ú¯ Ø¨Ø§Ú©Ø³\n",
        "        print(detections)\n",
        "        boxes = detections['detection_boxes'][0].numpy()\n",
        "        scores = detections['detection_scores'][0].numpy()\n",
        "        classes = detections['detection_classes'][0].numpy().astype(int)\n",
        "\n",
        "        # ðŸ“Œ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ØªØ´Ø®ÛŒØµâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± (Ù…Ø«Ù„Ø§Ù‹ ÙÙ‚Ø· Ø¨Ø§Ù„Ø§ÛŒ 50Ùª)\n",
        "        threshold = 0.5\n",
        "        valid_indices = np.where(scores > threshold)[0]\n",
        "\n",
        "        # ðŸ“Œ Ø±Ø³Ù… Ø¨Ø§Ù†Ø¯ÛŒÙ†Ú¯ Ø¨Ø§Ú©Ø³â€ŒÙ‡Ø§\n",
        "        img_bgr = cv2.imread(image_paths[i])  # ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†\n",
        "        img_bgr = cv2.resize(img_bgr, img_size)\n",
        "\n",
        "        for idx in valid_indices:\n",
        "            y1, x1, y2, x2 = boxes[idx]  # Ø¨Ø§Ù†Ø¯ÛŒÙ†Ú¯ Ø¨Ø§Ú©Ø³ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ (0 ØªØ§ 1)\n",
        "            h, w, _ = img_bgr.shape\n",
        "            x1, y1, x2, y2 = int(x1 * w), int(y1 * h), int(x2 * w), int(y2 * h)\n",
        "\n",
        "            label = f\"Class {classes[idx]}: {scores[idx]:.2f}\"\n",
        "            cv2.rectangle(img_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(img_bgr, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # ðŸ“Œ Ù†Ù…Ø§ÛŒØ´ Ù†ØªÛŒØ¬Ù‡\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "# ðŸŽ¯ Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª\n",
        "detect_objects(model, X_test, image_paths)\n"
      ]
    }
  ]
}